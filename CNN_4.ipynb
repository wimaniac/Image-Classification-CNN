{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNiv2pfjtP9E/Iye1OGdlz9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2nCQYOTEY2n8","executionInfo":{"status":"ok","timestamp":1728043367293,"user_tz":-420,"elapsed":2615,"user":{"displayName":"Xuân Quý","userId":"09451763879598723830"}},"outputId":"cd074b32-20b0-47bb-dc10-5b1baa70f180"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import zipfile\n","import io\n","from sklearn.model_selection import train_test_split\n","from PIL import Image,UnidentifiedImageError\n","import random\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["\n","# Đường dẫn tới file zip và thư mục giải nén\n","zip_file_path = '/content/drive/MyDrive/datasets/archive.zip'\n","extract_path = '/content/dataset/'\n","\n","# Mở file zip\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    # Danh sách các tệp trong file zip\n","    file_list = zip_ref.namelist()\n","\n","    # Lọc ra các tệp ảnh (.jpg)\n","    img_files = [file for file in file_list if file.endswith('.jpg')]"],"metadata":{"id":"Ryb5Es_JZWZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Danh sách lưu trữ ảnh và nhãn\n","images = []\n","labels = []\n","\n","# Tạo nhãn từ tên tệp\n","def get_label(filename):\n","    if 'cat' in filename.lower():\n","        return 0  # Mèo\n","    elif 'dog' in filename.lower():\n","        return 1  # Chó\n","    else:\n","        return None\n","\n","# Đọc tất cả các ảnh trong file zip\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    file_list = zip_ref.namelist()\n","\n","    # Lọc ra các tệp ảnh (.jpg)\n","    img_files = [file for file in file_list if file.endswith('.jpg')]\n","\n","    # Chọn ngẫu nhiên 2000 ảnh từ danh sách\n","    random_files = random.sample(img_files, 100)\n","\n","    for img_file in random_files:\n","        try:\n","            with zip_ref.open(img_file) as file:\n","                img = Image.open(io.BytesIO(file.read()))\n","\n","                # Chuyển đổi ảnh thành RGB (3 kênh màu)\n","                img = img.convert(\"RGB\")\n","                img = img.resize((150, 150))  # Thay đổi kích thước ảnh\n","                img_np = np.array(img)  # Chuyển đổi sang NumPy array (150, 150, 3)\n","\n","                label = get_label(img_file)\n","\n","                if label is not None:\n","                    images.append(img_np)\n","                    labels.append(label)\n","        except UnidentifiedImageError:\n","            print(f\"UnidentifiedImageError: Bỏ qua tệp không hợp lệ {img_file}\")\n","        except Exception as e:\n","            print(f\"Lỗi khác {img_file}: {e}\")\n","\n","# Chuyển đổi danh sách sang dạng NumPy array\n","images = np.array(images)\n","labels = np.array(labels)\n","\n","print('Số lượng ảnh đã đọc:', len(images))\n","print('Kích thước ảnh:', images.shape)\n"],"metadata":{"id":"sB5fzYqJc0iV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728043369160,"user_tz":-420,"elapsed":1157,"user":{"displayName":"Xuân Quý","userId":"09451763879598723830"}},"outputId":"f1f370d6-b34a-4805-920e-ee0310fce2df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Số lượng ảnh đã đọc: 100\n","Kích thước ảnh: (100, 150, 150, 3)\n"]}]},{"cell_type":"code","source":["# Chuẩn hóa giá trị pixel về khoảng [0, 1]\n","images = images.astype('float32') / 255.0\n","\n","# Chia dữ liệu thành tập huấn luyện và tập kiểm tra (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n","\n","print('Kích thước tập huấn luyện:', X_train.shape)\n","print('Kích thước tập kiểm tra:', X_test.shape)\n","print('Kích thước tập huấn luyện:', y_train.shape)\n","print('Kích thước tập kiểm tra:', y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLx7KwLz7eJd","executionInfo":{"status":"ok","timestamp":1728043369160,"user_tz":-420,"elapsed":6,"user":{"displayName":"Xuân Quý","userId":"09451763879598723830"}},"outputId":"840247dc-537e-468b-9873-a7c2a023ee4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Kích thước tập huấn luyện: (80, 150, 150, 3)\n","Kích thước tập kiểm tra: (20, 150, 150, 3)\n","Kích thước tập huấn luyện: (80,)\n","Kích thước tập kiểm tra: (20,)\n"]}]},{"cell_type":"code","source":["class Conv2D:\n","    def __init__(self, num_filters, kernel_size, input_channels, padding=0, stride=1):\n","        self.num_filters = num_filters\n","        self.kernel_size = kernel_size\n","        self.input_channels = input_channels\n","        self.padding = padding\n","        self.stride = stride\n","        self.weights = np.random.randn(kernel_size, kernel_size, input_channels, num_filters) * 0.01\n","        self.biases = np.zeros(num_filters)\n","        self.input = None\n","\n","    def forward(self, input):\n","        self.input = input\n","        batch_size, height, width, channels = input.shape\n","        output_height = (height - self.kernel_size + 2 * self.padding) // self.stride + 1\n","        output_width = (width - self.kernel_size + 2 * self.padding) // self.stride + 1\n","\n","        self.output = np.zeros((batch_size, output_height, output_width, self.num_filters))\n","\n","        padded_input = np.pad(input, ((0,0), (self.padding,self.padding), (self.padding,self.padding), (0,0)), mode='constant')\n","\n","        for b in range(batch_size):\n","            for i in range(output_height):\n","                for j in range(output_width):\n","                    for f in range(self.num_filters):\n","                        h_start = i * self.stride\n","                        h_end = h_start + self.kernel_size\n","                        w_start = j * self.stride\n","                        w_end = w_start + self.kernel_size\n","                        self.output[b, i, j, f] = np.sum(\n","                            padded_input[b, h_start:h_end, w_start:w_end, :] * self.weights[:, :, :, f]\n","                        ) + self.biases[f]\n","        return self.output\n","\n","    def backward(self, dout, learning_rate):\n","        batch_size, _, _, _ = self.input.shape\n","        dweights = np.zeros_like(self.weights)\n","        dbiases = np.zeros_like(self.biases)\n","        dinput = np.zeros_like(self.input)\n","\n","        padded_input = np.pad(self.input, ((0,0), (self.padding,self.padding), (self.padding,self.padding), (0,0)), mode='constant')\n","        padded_dinput = np.pad(dinput, ((0,0), (self.padding,self.padding), (self.padding,self.padding), (0,0)), mode='constant')\n","\n","        for b in range(batch_size):\n","            for i in range(dout.shape[1]):\n","                for j in range(dout.shape[2]):\n","                    for f in range(self.num_filters):\n","                        h_start = i * self.stride\n","                        h_end = h_start + self.kernel_size\n","                        w_start = j * self.stride\n","                        w_end = w_start + self.kernel_size\n","\n","                        dweights[:, :, :, f] += padded_input[b, h_start:h_end, w_start:w_end, :] * dout[b, i, j, f]\n","                        dbiases[f] += dout[b, i, j, f]\n","                        padded_dinput[b, h_start:h_end, w_start:w_end, :] += self.weights[:, :, :, f] * dout[b, i, j, f]\n","\n","        if self.padding > 0:\n","            dinput = padded_dinput[:, self.padding:-self.padding, self.padding:-self.padding, :]\n","        else:\n","            dinput = padded_dinput\n","\n","        self.weights -= learning_rate * dweights\n","        self.biases -= learning_rate * dbiases\n","\n","        return dinput\n"],"metadata":{"id":"REMHvq3M9dXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ReLU:\n","    def __init__(self):\n","        self.output = None\n","\n","    def forward(self, input):\n","        self.output = np.maximum(0, input)\n","        return self.output\n","\n","    def backward(self, upstream_gradient):\n","        return upstream_gradient * (self.output > 0)\n"],"metadata":{"id":"zpsVFHLI9mBs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MaxPooling:\n","    def __init__(self, pool_size, stride):\n","        self.pool_size = pool_size\n","        self.stride = stride\n","        self.input = None\n","\n","    def forward(self, input):\n","        self.input = input\n","        batch_size, height, width, channels = input.shape\n","        out_height = (height - self.pool_size) // self.stride + 1\n","        out_width = (width - self.pool_size) // self.stride + 1\n","        output = np.zeros((batch_size, out_height, out_width, channels))\n","\n","        for b in range(batch_size):\n","            for c in range(channels):\n","                for i in range(out_height):\n","                    for j in range(out_width):\n","                        h_start = i * self.stride\n","                        h_end = h_start + self.pool_size\n","                        w_start = j * self.stride\n","                        w_end = w_start + self.pool_size\n","                        output[b, i, j, c] = np.max(input[b, h_start:h_end, w_start:w_end, c])\n","\n","        return output\n","\n","    def backward(self, dout):\n","        dinput = np.zeros_like(self.input)\n","        batch_size, height, width, channels = self.input.shape\n","\n","        for b in range(batch_size):\n","            for c in range(channels):\n","                for i in range(dout.shape[1]):\n","                    for j in range(dout.shape[2]):\n","                        h_start = i * self.stride\n","                        h_end = h_start + self.pool_size\n","                        w_start = j * self.stride\n","                        w_end = w_start + self.pool_size\n","\n","                        pool_slice = self.input[b, h_start:h_end, w_start:w_end, c]\n","                        mask = pool_slice == np.max(pool_slice)\n","                        dinput[b, h_start:h_end, w_start:w_end, c] += mask * dout[b, i, j, c]\n","\n","        return dinput"],"metadata":{"id":"vxcECqdY9hu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Flatten:\n","    def __init__(self):\n","        self.input_shape = None\n","\n","    def forward(self, input_data):\n","        self.input_shape = input_data.shape\n","        return input_data.reshape(input_data.shape[0], -1)\n","\n","    def backward(self, dout):\n","        return dout.reshape(self.input_shape)\n","\n"],"metadata":{"id":"-hWAzxcV9lNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Dense:\n","    def __init__(self, input_size, output_size, activation=None):\n","        self.weights = np.random.randn(input_size, output_size) * 0.01  # Initialize weights\n","        self.biases = np.zeros((1, output_size))  # Initialize biases\n","        self.activation = activation\n","\n","    def forward(self, input_data):\n","        if self.weights is None or self.biases is None:\n","            raise ValueError(\"Weights or biases are not initialized.\")\n","        self.input_data = input_data  # Save input for backward pass\n","        z = np.dot(input_data, self.weights) + self.biases\n","        return self.activation(z) if self.activation else z\n","\n","    def backward(self, dout, learning_rate):\n","        # Calculate gradients\n","        grad_input = np.dot(dout, self.weights.T)  # Gradient with respect to the input\n","        grad_weights = np.dot(self.input_data.T, dout)  # Gradient with respect to weights\n","        grad_biases = np.sum(dout, axis=0, keepdims=True)  # Gradient with respect to biases\n","\n","        # Update weights and biases\n","        self.weights -= learning_rate * grad_weights\n","        self.biases -= learning_rate * grad_biases\n","\n","        return grad_input  # Return the gradient to propagate to the previous layer\n"],"metadata":{"id":"OIxLGH7R9oAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Sigmoid:\n","    def __init__(self):\n","        self.output = None\n","\n","    def forward(self, input):\n","        input = np.clip(input, -500, 500)\n","        self.output = 1 / (1 + np.exp(-input))\n","        return self.output\n","\n","    def backward(self, dout):\n","        return dout * self.output * (1 - self.output)\n"],"metadata":{"id":"mhXv4EQV9o2m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder\n","\n","encoder = OneHotEncoder()\n","y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1)).toarray()\n","y_test_encoded = encoder.transform(y_test.reshape(-1, 1)).toarray()\n","\n","print(\"Kích thước y_train sau one-hot encoding:\", y_train_encoded.shape)\n","print(\"Kích thước y_test sau one-hot encoding:\", y_test_encoded.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woU1NdomNj5C","executionInfo":{"status":"ok","timestamp":1728043369160,"user_tz":-420,"elapsed":4,"user":{"displayName":"Xuân Quý","userId":"09451763879598723830"}},"outputId":"ad1c8f65-1e6c-4d91-ed54-fb6c17456794"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Kích thước y_train sau one-hot encoding: (80, 2)\n","Kích thước y_test sau one-hot encoding: (20, 2)\n"]}]},{"cell_type":"code","source":["class CNN:\n","    def __init__(self, num_classes):\n","        self.conv1 = Conv2D(32, 3, 1)\n","        self.pool1 = MaxPooling(2, 2)\n","        self.conv2 = Conv2D(64, 3, 1)\n","        self.pool2 = MaxPooling(2, 2)\n","        self.flatten = Flatten()\n","        self.fc1 = Dense(128, 128, activation='relu')  # Đặt kích thước đầu vào dựa trên kích thước thực tế\n","        self.fc2 = Dense(128, num_classes, activation='softmax')\n","\n","    def build(self, input_shape):\n","        # Truyền qua các lớp để xác định kích thước đầu ra\n","        x = np.zeros(input_shape)\n","        x = self.conv1.forward(x)\n","        x = self.pool1.forward(x)\n","        x = self.conv2.forward(x)\n","        x = self.pool2.forward(x)\n","        x = self.flatten.forward(x)\n","\n","        # Đặt kích thước đầu vào cho lớp Dense đầu tiên\n","        self.fc1 = Dense(x.shape[1], 128, activation='relu')  # Cập nhật kích thước đầu vào cho fc1\n","        self.fc2 = Dense(128, num_classes, activation='softmax')  # Giữ nguyên fc2\n","\n","    def forward(self, x):\n","        x = self.conv1.forward(x)\n","        x = self.pool1.forward(x)\n","        x = self.conv2.forward(x)\n","        x = self.pool2.forward(x)\n","        x = self.flatten.forward(x)\n","        x = self.fc1.forward(x)\n","        x = self.fc2.forward(x)\n","        return x\n"],"metadata":{"id":"-iEH2xFY21dS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CrossEntropyLoss:\n","    def compute_loss(self, predictions, targets):\n","        predictions = np.clip(predictions, 1e-9, 1 - 1e-9)  # Prevent log(0)\n","        N = predictions.shape[0]\n","        loss = -np.sum(targets * np.log(predictions)) / N\n","        return loss\n","\n","    def backward(self, predictions, targets):\n","        return predictions - targets"],"metadata":{"id":"8sg3vP7DZg0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, X_train, y_train, X_test, y_test, epochs, batch_size, learning_rate):\n","    train_losses = []\n","    test_losses = []\n","    train_accuracies = []\n","    test_accuracies = []\n","    loss_fn = CrossEntropyLoss()\n","\n","    for epoch in range(epochs):\n","        print(f\"Epoch {epoch + 1}/{epochs}\")\n","\n","        # Training\n","        train_loss = 0\n","        train_predictions = []\n","        num_batches = len(X_train) // batch_size\n","\n","        with tqdm(total=num_batches, desc=f\"Training Epoch {epoch + 1}\", unit=\"batch\") as pbar:\n","            for i in range(0, len(X_train), batch_size):\n","                batch_X = X_train[i:i + batch_size]\n","                batch_y = y_train[i:i + batch_size]\n","\n","                # Forward pass\n","                output = model.forward(batch_X)\n","                loss = loss_fn.compute_loss(output, batch_y)\n","                train_loss += loss\n","\n","                # Backward pass\n","                dout = loss_fn.backward(output, batch_y)\n","                model.backward(dout, learning_rate)\n","\n","                train_predictions.extend(np.argmax(output, axis=1))\n","\n","                pbar.update(1)\n","\n","        train_loss /= num_batches\n","        train_accuracy = accuracy_score(np.argmax(y_train, axis=1), train_predictions)\n","        train_losses.append(train_loss)\n","        train_accuracies.append(train_accuracy)\n","\n","        # Testing\n","        test_output = model.forward(X_test)\n","        test_loss = loss_fn.compute_loss(test_output, y_test)\n","        test_predictions = np.argmax(test_output, axis=1)\n","        test_accuracy = accuracy_score(np.argmax(y_test, axis=1), test_predictions)\n","        test_losses.append(test_loss)\n","        test_accuracies.append(test_accuracy)\n","\n","        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n","        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n","        print(\"-----------------------------\")\n","\n","    return train_losses, test_losses, train_accuracies, test_accuracies\n","\n","# Initialize model\n","num_classes = 2  # For binary classification (cat vs dog)\n","model = CNN(num_classes)\n"],"metadata":{"id":"iOHfA_Vp9kM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_losses, test_losses, train_accuracies, test_accuracies = train(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=8, learning_rate=0.001)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"FbvveepTLNZZ","executionInfo":{"status":"error","timestamp":1728043935789,"user_tz":-420,"elapsed":93507,"user":{"displayName":"Xuân Quý","userId":"09451763879598723830"}},"outputId":"a1808b6e-2bd6-4527-f876-faa413adfe54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch 1:   0%|          | 0/10 [01:33<?, ?batch/s]\n"]},{"output_type":"error","ename":"ValueError","evalue":"shapes (8,82944) and (128,128) not aligned: 82944 (dim 1) != 128 (dim 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-156-ba2c82965449>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-151-cedb0b9996dd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, X_test, y_test, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-149-f2db730530f4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-146-b29e7d7f49bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Weights or biases are not initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m  \u001b[0;31m# Save input for backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (8,82944) and (128,128) not aligned: 82944 (dim 1) != 128 (dim 0)"]}]}]}